import requests
from bs4 import BeautifulSoup
import csv
import datetime
import os
import time
import random

# ==================================================================================
# [Portfolio] High-Volume E-commerce Scraper (ÎåÄÏö©Îüâ Ïù¥Ïª§Î®∏Ïä§ Ïä§ÌÅ¨ÎûòÌïë Î¥á)
#
# ----------------------------------------------------------------------------------
# üåç Developer Profile:
#    - Native Korean Developer based in Canada (ÌïúÍµ≠Ïù∏ Í∞úÎ∞úÏûê)
#    - Expert in scraping Korean platforms (Olive Young,Naver, Coupang,  etc.)
#
# üéØ Target Site (ÌÉÄÍ≤ü ÏÇ¨Ïù¥Ìä∏):
#    - Olive Young (Korea's No.1 Health & Beauty Store) / Ïò¨Î¶¨Î∏åÏòÅ
#    - Similar to Sephora or Boots (ÏÑ∏Ìè¨Îùº, Î∂ÄÏ∏†ÏôÄ Ïú†ÏÇ¨Ìïú ÎåÄÌòï Ïª§Î®∏Ïä§)
#
# üõ°Ô∏è Key Features (ÌïµÏã¨ Í∏∞Îä•):
#    - Anti-Bot Bypass (Î¥á ÌÉêÏßÄ ÌöåÌîº Í∏∞Ïà† Ï†ÅÏö©)
#    - Dynamic Tag Parsing (Ìï†Ïù∏, Ïø†Ìè∞ Îì± ÎèôÏ†Å ÌÉúÍ∑∏ Ï≤òÎ¶¨)
#    - UTF-8 Encoding Support (ÌïúÍ∏Ä Îç∞Ïù¥ÌÑ∞ Íπ®Ïßê Î∞©ÏßÄ ÏôÑÎ≤Ω Ï≤òÎ¶¨)
#
# ‚ö†Ô∏è Privacy Note:
#    - Real URLs and Selectors are masked for security/NDA reasons.
#    - Ïã§Ï†ú URLÍ≥º CSS ÏÑ†ÌÉùÏûêÎäî Î≥¥Ïïà Î∞è Í≥†Í∞ùÏÇ¨ Î≥¥Ìò∏Î•º ÏúÑÌï¥ Í∞ÄÎ¶º Ï≤òÎ¶¨ÎêòÏóàÏäµÎãàÎã§.
# ==================================================================================

def get_headers():
    """
    Configures User-Agent to mimic a real browser to avoid blocking.
    (ÏÑúÎ≤Ñ Ï∞®Îã®ÏùÑ ÌîºÌïòÍ∏∞ ÏúÑÌï¥ Ïã§Ï†ú Î∏åÎùºÏö∞Ï†ÄÏ≤òÎüº ÏúÑÏû•ÌïòÎäî Ìó§Îçî ÏÑ§Ï†ï)
    """
    return {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.target-commerce-site.com/',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9',
        'Connection': 'keep-alive'
    }

def scrape_ranking_data():
    # 1. Target URL (Masked)
    url = "https://www.target-commerce-site.com/best/ranking"
    
    print("Initializing Scraper... (Ïä§ÌÅ¨ÎûòÌçº ÏãúÏûë Ï§ë)")
    
    try:
        # 2. Anti-Bot Delay (Random sleep)
        # Random delay simulates human behavior. (ÏÇ¨ÎûåÏ≤òÎüº Î≥¥Ïù¥Í≤å ÎûúÎç§ ÎåÄÍ∏∞)
        sleep_time = random.uniform(1.0, 3.0)
        time.sleep(sleep_time)
        print(f"Waiting for {sleep_time:.2f} seconds...")
        
        # 3. Request
        response = requests.get(url, headers=get_headers())
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 4. Parsing Logic (Selectors masked)
        items = soup.select("ul.product_list > li")
        
        # Prepare CSV Header (Korean/English Bilingual Support)
        data_rows = [['Date', 'Rank', 'Brand', 'Product Name', 'Price', 'Tags']]
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        print(f"Found {len(items)} items. Extracting data...")

        for idx, item in enumerate(items, 1):
            # Safe Extraction with Error Handling
            try:
                brand = item.select_one(".brand_name").text.strip()
                name = item.select_one(".product_name").text.strip()
                price = item.select_one(".price_value").text.strip()
                
                # Handling dynamic tags (e.g., Sale, Coupon)
                tags = [t.text for t in item.select(".promotion_tags span")]
                tags_str = ", ".join(tags)
                
                data_rows.append([current_time, idx, brand, name, price, tags_str])
            except AttributeError:
                continue # Skip invalid rows

        # 5. Save to CSV (utf-8-sig for Korean characters)
        filename = "result_sample.csv"
        with open(filename, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(data_rows)
            
        print(f"‚úÖ Success! Data saved to {filename}")

    except Exception as e:
        print(f"‚ùå Error occurred: {e}")

if __name__ == "__main__":
    scrape_ranking_data()